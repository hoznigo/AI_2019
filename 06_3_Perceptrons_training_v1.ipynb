{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_3_Perceptrons_training_v1.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"IEh7jdAcD3Dv","colab_type":"text"},"cell_type":"markdown","source":["### Perceptrons - Training"]},{"metadata":{"id":"KrEed6J9D3Dz","colab_type":"text"},"cell_type":"markdown","source":["Note for 717005@ Hallym University !"]},{"metadata":{"id":"hAYz7mUFD3D0","colab_type":"text"},"cell_type":"markdown","source":["* Make a prediction with weights"]},{"metadata":{"id":"PjU1fdEoD3D1","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict(X, w):\n","    bias = w[0]\n","    activation = bias + w[1]* X[0] + w[2]* X[1]\n","    if activation >= 0.0:\n","        return 1.0\n","    else:\n","        return 0.0 # 6_2와는 다르게 w의 값이 주어지지 아니하였다."],"execution_count":0,"outputs":[]},{"metadata":{"id":"ow1B2zp4D3D9","colab_type":"text"},"cell_type":"markdown","source":["* Estimate Perceptron weights using stochastic gradient descent"]},{"metadata":{"id":"G4Do5H6dD3D-","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_weights(train, l_rate, n_epoch): # n_epoch : 시도 하는 횟수\n","    weights = [0, 0, 0] # weights = [0.0 for i in range(len(train[0]))] 이전 code\n","    print(weights)\n","    print(\"--------------------------------------------\")\n","    \n","    vb = []\n","    vw0 = []\n","    vw1 = []\n","    \n","    for epoch in range(n_epoch):\n","        sum_error = 0.0\n","        for row in train:\n","            prediction = predict(row, weights) # computer가 정한 임의의 weights\n","            jd = row[-1] # answer는 -1을 하는 것이다.\n","            error = jd - prediction # error = row[-1] - prediction\n","            sum_error += error**2\n","            \n","            weights[0] = weights[0] + l_rate * error # running rate의 개념\n","            for i in range(len(row)-1):\n","                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n","            \n","            vb.append(weights[0])\n","            vw0.append(weights[1])\n","            vw1.append(weights[2])\n","            \n","        print('epoch={}, error={}'.format(epoch, sum_error))\n","    return weights, vb, vw0, vw1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1UEnQx0rD3EA","colab_type":"code","colab":{}},"cell_type":"code","source":["# training set\n","dataset = [[2.7810836,2.550537003,0],\n","    [1.465489372,2.362125076,0],\n","    [3.396561688,4.400293529,0],\n","    [1.38807019,1.850220317,0],\n","    [3.06407232,3.005305973,0],\n","    [7.627531214,2.759262235,1],\n","    [5.332441248,2.088626775,1],\n","    [6.922596716,1.77106367,1],\n","    [8.675418651,-0.242068655,1],\n","    [7.673756466,3.508563011,1]]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WfrQk7eVD3EE","colab_type":"text"},"cell_type":"markdown","source":["* Hyperparameters"]},{"metadata":{"id":"lOBseT3yD3EF","colab_type":"code","colab":{}},"cell_type":"code","source":["l_rate = 0.1 #이 숫자가 커지면 위의 sum_error += error**2의 값이 커지게 된다.\n","n_epoch = 5"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-AxxPctpD3EH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"5c744220-5341-4ecc-e6d1-f15099368141","executionInfo":{"status":"ok","timestamp":1554950832159,"user_tz":-540,"elapsed":852,"user":{"displayName":"Hojun Kang","photoUrl":"https://lh4.googleusercontent.com/-T5iXQ3gwkEs/AAAAAAAAAAI/AAAAAAAAFvw/01W6d6oxDtY/s64/photo.jpg","userId":"10664325841753232023"}}},"cell_type":"code","source":["weights, vb, vw0, vw1 = train_weights(dataset, l_rate, n_epoch) #위의 train_weight에 row는 dataset이다."],"execution_count":47,"outputs":[{"output_type":"stream","text":["[0, 0, 0]\n","--------------------------------------------\n","epoch=0, error=2.0\n","epoch=1, error=1.0\n","epoch=2, error=0.0\n","epoch=3, error=0.0\n","epoch=4, error=0.0\n"],"name":"stdout"}]},{"metadata":{"id":"aFBJjlAJD3EO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"d03cf7ce-7bd2-444e-ebdb-6106441320b4","executionInfo":{"status":"ok","timestamp":1554950832161,"user_tz":-540,"elapsed":832,"user":{"displayName":"Hojun Kang","photoUrl":"https://lh4.googleusercontent.com/-T5iXQ3gwkEs/AAAAAAAAAAI/AAAAAAAAFvw/01W6d6oxDtY/s64/photo.jpg","userId":"10664325841753232023"}}},"cell_type":"code","source":["print(weights)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["[-0.1, 0.20653640140000007, -0.23418117710000003]\n"],"name":"stdout"}]},{"metadata":{"id":"7hQGEa5lSiCW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"dffbb0cd-0a3e-4ddc-bff8-6ae77f499ec5","executionInfo":{"status":"error","timestamp":1554950832175,"user_tz":-540,"elapsed":833,"user":{"displayName":"Hojun Kang","photoUrl":"https://lh4.googleusercontent.com/-T5iXQ3gwkEs/AAAAAAAAAAI/AAAAAAAAFvw/01W6d6oxDtY/s64/photo.jpg","userId":"10664325841753232023"}}},"cell_type":"code","source":["pred = predict([3.8 3], weights)\n","print(pred)"],"execution_count":49,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-8dc63651ae06>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pred = predict([3.8 3], weights)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"metadata":{"id":"lBrwMfiHOrBS","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"whO_O5u3OyLO","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.plot(vb ,'r')\n","plt.plot(vw0, 'g')\n","plt.plot(vw1, 'b')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QLm1P2AcD3ES","colab_type":"text"},"cell_type":"markdown","source":["* Why ?"]},{"metadata":{"id":"PXvZZbJAD3ET","colab_type":"text"},"cell_type":"markdown","source":["partial derivative with respect to m"]},{"metadata":{"id":"gHpqyyHYD3EU","colab_type":"text"},"cell_type":"markdown","source":["$$ \\frac{\\partial J(m,b)}{\\partial m} =  \\frac{1}{n}\\sum_{i=1}^{n} -2 x^{(i)} (y_{i}-(mx^{(i)} + b)) \\\\\n","= \\frac{2}{n}\\sum_{i=1}^{n} x^{(i)} ((mx^{(i)} + b)-y^{(i)}) \\\\\n","= \\frac{2}{n}\\sum_{i=1}^{n} x^{(i)} (\\hat{y}^{(i)} -y^{(i)})$$"]},{"metadata":{"id":"AK5AXJ7GD3EV","colab_type":"text"},"cell_type":"markdown","source":["partial derivative with respect to b"]},{"metadata":{"id":"cn82wuLtD3EV","colab_type":"text"},"cell_type":"markdown","source":["$$ \\frac{\\partial J(m,b)}{\\partial b} =  \\frac{1}{n}\\sum_{i=1}^{n} -2  (y^{(i)}-(mx^{(i)} + b)) \\\\\n","= \\frac{-2}{n}\\sum_{i=1}^{n}  (y^{(i)}-(mx^{(i)} + b)) \\\\\n","= \\frac{2}{n}\\sum_{i=1}^{n}  (\\hat{y}^{(i)}-y^{(i)}) \\\\ $$\n"]},{"metadata":{"id":"5aoO6c_FD3EW","colab_type":"text"},"cell_type":"markdown","source":["Partial derivatives : https://www.mathsisfun.com/calculus/derivatives-partial.html"]},{"metadata":{"id":"QB17m8dbD3EX","colab_type":"text"},"cell_type":"markdown","source":["* References"]},{"metadata":{"id":"2q5i-2JtD3EX","colab_type":"text"},"cell_type":"markdown","source":["```\n","https://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/\n","```"]}]}